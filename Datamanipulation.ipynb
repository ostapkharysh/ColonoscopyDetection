{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats, optimize, interpolate\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bits</th>\n",
       "      <th>non_zero_pixels</th>\n",
       "      <th>movement_level</th>\n",
       "      <th>mean</th>\n",
       "      <th>sub_mean_1</th>\n",
       "      <th>sub_mean_2</th>\n",
       "      <th>sub_mean_3</th>\n",
       "      <th>sub_mean_4</th>\n",
       "      <th>var_sub_blocks</th>\n",
       "      <th>sobel_h</th>\n",
       "      <th>...</th>\n",
       "      <th>cost_2</th>\n",
       "      <th>quality</th>\n",
       "      <th>intra_parts</th>\n",
       "      <th>skip_parts</th>\n",
       "      <th>inter_16x16_parts</th>\n",
       "      <th>inter_4x4_parts</th>\n",
       "      <th>inter_other_parts</th>\n",
       "      <th>frame_width</th>\n",
       "      <th>frame_height</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.235171</td>\n",
       "      <td>0.283816</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.051159</td>\n",
       "      <td>0.119325</td>\n",
       "      <td>0.157762</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.201656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>0.244842</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.076514</td>\n",
       "      <td>0.067665</td>\n",
       "      <td>0.187908</td>\n",
       "      <td>0.180386</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.200689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037362</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098093</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.921025</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.051514</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.095587</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.111573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.245441</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.027827</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.049414</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.055122</td>\n",
       "      <td>0.067872</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437225</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>0.328660</td>\n",
       "      <td>0.288658</td>\n",
       "      <td>0.032566</td>\n",
       "      <td>0.458804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410566</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bits  non_zero_pixels  movement_level      mean  sub_mean_1  \\\n",
       "0  0.235171         0.283816        0.025359  0.002366    0.061133   \n",
       "1  0.044435         0.025362        0.244842  0.003134    0.076514   \n",
       "2  0.098093         0.109903        0.921025  0.001312    0.051514   \n",
       "3  0.245441         0.239130        0.027827  0.001109    0.049414   \n",
       "4  0.437225         0.489130        0.025254  0.006070    0.264160   \n",
       "\n",
       "   sub_mean_2  sub_mean_3  sub_mean_4  var_sub_blocks   sobel_h  ...  \\\n",
       "0    0.051159    0.119325    0.157762        0.000674  0.201656  ...   \n",
       "1    0.067665    0.187908    0.180386        0.002005  0.200689  ...   \n",
       "2    0.018864    0.095587    0.032320        0.002125  0.111573  ...   \n",
       "3    0.005741    0.055122    0.067872        0.001425  0.091231  ...   \n",
       "4    0.062846    0.328660    0.288658        0.032566  0.458804  ...   \n",
       "\n",
       "     cost_2  quality  intra_parts  skip_parts  inter_16x16_parts  \\\n",
       "0  0.239385        1            0           0                  0   \n",
       "1  0.037362        3            5           0                  2   \n",
       "2  0.016832        0            6           1                  1   \n",
       "3  0.061133        0            0           0                  2   \n",
       "4  0.410566        1           14           0                  0   \n",
       "\n",
       "   inter_4x4_parts  inter_other_parts  frame_width  frame_height  relevant  \n",
       "0                0                 13            1             1         1  \n",
       "1                0                  2            2             2         1  \n",
       "2                0                  0            3             3         1  \n",
       "3                1                  7            1             1         1  \n",
       "4                0                  0            1             1         1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tryMe_balanced.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null, nan\n",
    "df.isnull().any()\n",
    "df  = df.dropna() # by now\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10, 7))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=90)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected correlations\n",
    "print(df[\"quality\"].corr(df[\"relevant\"]))\n",
    "print(df[\"bits\"].corr(df[\"relevant\"]))\n",
    "df[\"quality\"].corr(df[\"bits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a table of categorical and continuous data\n",
    "cat = df.loc[:, df.nunique() < 200]\n",
    "cont = df.loc[:, df.nunique() >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "cont_val = cont.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "cont_scaled = min_max_scaler.fit_transform(cont_val)\n",
    "cont_sc = pd.DataFrame(cont_scaled)\n",
    "cont_sc.columns=cont.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sc = cont_sc.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cont_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont.corrwith(cat.relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sc.corrwith(cat.relevant)  # looks like normalozation of categorical variaables doesn't have an affect on correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caregorical data factorization\n",
    "cat_fc =  pd.DataFrame(cat.apply(lambda x: pd.factorize(x)[0]))\n",
    "cat_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.corrwith(cat.relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fc.corrwith(cat.relevant) # feels like some date is not categorical as corelation reduces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6979\n",
      "recall 0.6639\n",
      "specificity 0.7319\n",
      "precision 0.7116\n"
     ]
    }
   ],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "#print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "\n",
    "accuracy = (TP + TN) / float(TP+TN+FP+FN) # metrics.accuracy_score(y_test, y_pred)\n",
    "sensitiviy = TP / float(TP+FN)  #recall metrics.recall_score(y_test, y_pred)\n",
    "specificity = TN / float(TN+FP) #when the actual value is negative, how often is the predicion correct?\n",
    "precision = TP / float(TP+FP)   #metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"accuracy\", accuracy.round(4))  \n",
    "print(\"recall\", sensitiviy.round(4))\n",
    "print(\"specificity\", specificity.round(4))\n",
    "print(\"precision\",precision.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6246\n",
      "recall 0.492\n",
      "specificity 0.6335\n",
      "precision 0.626\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test2,y_pred2)\n",
    "\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "\n",
    "accuracy = (TP + TN) / float(TP+TN+FP+FN) # metrics.accuracy_score(y_test, y_pred)\n",
    "sensitiviy = TP / float(TP+TN)  #recall metrics.recall_score(y_test, y_pred)\n",
    "specificity = TN / float(TN+FP) #when the actual value is negative, how often is the predicion correct?\n",
    "precision = TP / float(TP+FP)   #metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"accuracy\", accuracy.round(4))  \n",
    "print(\"recall\", sensitiviy.round(4))\n",
    "print(\"specificity\", specificity.round(4))\n",
    "print(\"precision\",precision.round(4))\n",
    "\n",
    "\n",
    "#tree.plot_tree(clf) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7173\n",
      "recall 0.4841\n",
      "specificity 0.7389\n",
      "precision 0.7264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train3,y_train3)\n",
    "\n",
    "y_pred3=clf.predict(X_test3)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test3,y_pred3)\n",
    "\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "\n",
    "accuracy = (TP + TN) / float(TP+TN+FP+FN) # metrics.accuracy_score(y_test, y_pred)\n",
    "sensitiviy = TP / float(TP+TN)  #recall metrics.recall_score(y_test, y_pred)\n",
    "specificity = TN / float(TN+FP) #when the actual value is negative, how often is the predicion correct?\n",
    "precision = TP / float(TP+FP)   #metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"accuracy\", accuracy.round(4))  \n",
    "print(\"recall\", sensitiviy.round(4))\n",
    "print(\"specificity\", specificity.round(4))\n",
    "print(\"precision\",precision.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([cont_sc, cat_fc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_t[data_t.columns[:-1]]\n",
    "y = data_t[data_t.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "\n",
    "accuracy = (TP + TN) / float(TP+TN+FP+FN) # metrics.accuracy_score(y_test, y_pred)\n",
    "sensitiviy = TP / float(TP+FN)  #recall metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "specificity = TN / float(TN+FP) #when the actual value is negative, how often is the predicion correct?\n",
    "precision = TP / float(TP+FP)   #metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"accuracy\", accuracy.round(4))  \n",
    "print(\"recall\", sensitiviy.round(4))\n",
    "print(\"specificity\", specificity.round(4))\n",
    "print(\"precision\",precision.round(4))\n",
    "\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X = data_t[data_t.columns[:-1]]\n",
    "y = data_t[data_t.columns[-1]]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test2,y_pred2)\n",
    "\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "\n",
    "accuracy = (TP + TN) / float(TP+TN+FP+FN) # metrics.accuracy_score(y_test, y_pred)\n",
    "sensitiviy = TP / float(TP+FN)  #recall metrics.recall_score(y_test, y_pred)\n",
    "specificity = TN / float(TN+FP) #when the actual value is negative, how often is the predicion correct?\n",
    "precision = TP / float(TP+FP)   #metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"accuracy\", accuracy.round(4))  \n",
    "print(\"recall\", sensitiviy.round(4))\n",
    "print(\"specificity\", specificity.round(4))\n",
    "print(\"precision\",precision.round(4))\n",
    "\n",
    "\n",
    "\n",
    "print(confusion)\n",
    "#tree.plot_tree(clf) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = data_t[data_t.columns[:-1]]\n",
    "y = data_t[data_t.columns[-1]]\n",
    "\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train3,y_train3)\n",
    "\n",
    "y_pred3=clf.predict(X_test3)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test3,y_pred3)\n",
    "\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "\n",
    "accuracy = (TP + TN) / float(TP+TN+FP+FN) # metrics.accuracy_score(y_test, y_pred)\n",
    "sensitiviy = TP / float(TP+FN)  #recall metrics.recall_score(y_test, y_pred)\n",
    "specificity = TN / float(TN+FP) #when the actual value is negative, how often is the predicion correct?\n",
    "precision = TP / float(TP+FP)   #metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy\", accuracy.round(4))  \n",
    "print(\"recall\", sensitiviy.round(4))\n",
    "print(\"specificity\", specificity.round(4))\n",
    "print(\"precision\",precision.round(4))\n",
    "\n",
    "\n",
    "print(confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#KMEANS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.cm as cm\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "kmeans.fit(data_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(data_t)\n",
    "    sse.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 11), sse)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.title(\"Elbow method\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = KneeLocator(range(1, 11), \n",
    "                 sse, \n",
    "                 curve=\"convex\", \n",
    "                 direction=\"decreasing\")\n",
    "kl.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list holds the silhouette coefficients for each k\n",
    "silhouette_coefficients = []\n",
    "\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(data_t)\n",
    "    score = silhouette_score(data_t, kmeans.labels_)\n",
    "    silhouette_coefficients.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, 11), silhouette_coefficients)\n",
    "plt.xticks(range(2, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, true_labels = make_moons(\n",
    "    n_samples=250, \n",
    "    noise=0.05, \n",
    "    random_state=42  )\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "dbscan = DBSCAN(eps=0.3)\n",
    "\n",
    "# Fit the algorithms to the features\n",
    "kmeans.fit(scaled_features)\n",
    "dbscan.fit(scaled_features)\n",
    "\n",
    " # Compute the silhouette scores for each algorithm\n",
    "kmeans_silhouette = silhouette_score(\n",
    "    scaled_features, kmeans.labels_\n",
    "     ).round(2)\n",
    "dbscan_silhouette = silhouette_score(\n",
    "    scaled_features, dbscan.labels_\n",
    "     ).round (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silhouette\n",
    "dbscan_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_kmeans = adjusted_rand_score(true_labels, kmeans.labels_)\n",
    "ari_dbscan = adjusted_rand_score(true_labels, dbscan.labels_)\n",
    "\n",
    "print(round(ari_kmeans, 2))\n",
    " \n",
    "\n",
    "print(round(ari_dbscan, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "import pandas\n",
    "\n",
    "mat = data_t.values\n",
    "# Using sklearn\n",
    "km = sklearn.cluster.KMeans(n_clusters=5)\n",
    "km.fit(mat)\n",
    "# Get cluster assignment labels\n",
    "labels = km.labels_\n",
    "# Format results as a DataFrame\n",
    "results = pandas.DataFrame([data_t.index,labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_analysis(X, X_pca, range_n_clusters):\n",
    "    \n",
    "    for n_clusters in range_n_clusters:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(18, 7)\n",
    "\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            y_lower = y_upper + 10  \n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  \n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "        ax2.scatter(X_pca[0], X_pca[1], c=colors)\n",
    "    \n",
    "        ax2.set_title(\"The visualization of the clustered data.\")\n",
    "        ax2.set_xlabel(\"PCA component 1\")\n",
    "        ax2.set_ylabel(\"PCA component 2\")\n",
    "\n",
    "        plt.suptitle((\"\\nSilhouette analysis for KMeans clustering \"\n",
    "                      \"with n_clusters = %d\" % n_clusters),\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=2)\n",
    "data_pca=pd.DataFrame(pca.fit_transform(data_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_analysis(np.array(data_t), \n",
    "                    cont_pca, \n",
    "                    [2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_linkage = linkage(data_t,\n",
    "                            method = 'ward', \n",
    "                            metric = 'euclidean'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('BITS')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "dendrogram(\n",
    "    distances_linkage,\n",
    "    #color_threshold = 0,\n",
    "    no_labels = True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('BITS')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "dendrogram(\n",
    "    distances_linkage,\n",
    "    truncate_mode='lastp',\n",
    "    p=10,\n",
    "    show_leaf_counts=True,    #False \n",
    "    show_contracted=True,\n",
    "    #color_threshold = 0,\n",
    "    no_labels = True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcluster = AgglomerativeClustering(n_clusters = 3,\n",
    "                                   affinity = 'euclidean',\n",
    "                                   linkage = 'ward')\n",
    "hcluster.fit_predict(data_t)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "\n",
    "plt.scatter(data_pca[0], \n",
    "            data_pca[1],\n",
    "            c=hcluster.labels_\n",
    "           )\n",
    "\n",
    "plt.title(\"The visualization of the clustered data\")\n",
    "plt.xlabel(\"PCA component 1\")\n",
    "plt.ylabel(\"PCA component 2\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 3)\n",
    "kmeans.fit(data_t)\n",
    "data_t['cluster'] = kmeans.labels_.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data_t.sort_values(by='cluster'), \n",
    "              x='cluster', \n",
    "              hue='relevant',\n",
    "              palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_t, \n",
    "             hue = 'cluster',\n",
    "             palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
